{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a637f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687fd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração\n",
    "path = \"hdfs://spark01:9000/datasets/air_quality/\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"tp_final_jean_luiz\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(path, header=True)\n",
    "\n",
    "# Convertendo para double, porque será necessário posteriormente\n",
    "df = df.withColumn(\"lat\",df.lat.cast('double'))\n",
    "df = df.withColumn(\"lon\",df.lon.cast('double'))\n",
    "df = df.withColumn(\"pressure\",df.pressure.cast('double'))\n",
    "df = df.withColumn(\"temperature\",df.temperature.cast('double'))\n",
    "df = df.withColumn(\"humidity\",df.humidity.cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50154996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=======================>                                (17 + 2) / 41]"
     ]
    }
   ],
   "source": [
    "# 1. Realizar uma análise da correlação entre os atributos presentes na base de dados \n",
    "# (pressão, temperatura, umidade, P1 (PM10) e P2 (PM2,5)).\n",
    "\n",
    "# Filtrando apenas as colunas desejadas\n",
    "columns = ['pressure','temperature','humidity'] # faltando P1 e P2 no dataframe \n",
    "df_filtered = df.select(*columns)\n",
    "df_filtered = df_filtered.filter(df_filtered.pressure.isNotNull())\n",
    "df_filtered = df_filtered.filter(df_filtered.temperature.isNotNull())\n",
    "df_filtered = df_filtered.filter(df_filtered.humidity.isNotNull())\n",
    "\n",
    "# Criando coluna de vector\n",
    "vector_column = \"vector_column\"\n",
    "assembler = VectorAssembler(inputCols=df_filtered.columns, outputCol=vector_column)\n",
    "df_vector = assembler.transform(df_filtered).select(vector_column)\n",
    "\n",
    "# Obtendo matriz de correlação\n",
    "matrix = Correlation.corr(df_vector, vector_column).collect()[0][0]\n",
    "corrmatrix = matrix.toArray().tolist()\n",
    "\n",
    "# Plotando\n",
    "def plot_corr_matrix(correlations,attr,fig_no):\n",
    "    fig=plt.figure(fig_no)\n",
    "    ax=fig.add_subplot(111)\n",
    "    ax.set_title(\"Correlation Matrix\")\n",
    "    ax.set_xticklabels(['']+attr)\n",
    "    ax.set_yticklabels(['']+attr)\n",
    "    cax=ax.matshow(correlations,vmax=1,vmin=-1)\n",
    "    fig.colorbar(cax)\n",
    "    plt.show()\n",
    "plot_corr_matrix(corrmatrix, columns, 234)\n",
    "\n",
    "spark.createDataFrame(corrmatrix,columns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515cae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
